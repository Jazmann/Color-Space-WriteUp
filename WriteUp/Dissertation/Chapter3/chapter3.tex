%\newcommand{\unitDst}{\text{uDst}} % Destination in the unit range 0:1
%\newcommand{\uDst}{\unitDst}       % Destination in the unit range 0:1
%\newcommand{\intDst}{\text{iDst}}  % Destination in the integer range dstMin:dstMax
%\newcommand{\iDst}{\intDst}        % Destination in the integer range dstMin:dstMax
%\newcommand{\dstMax}{\text{dstMax}}      % Destination integer range maximum
%\newcommand{\dstMin}{\text{dstMin}}      % Destination integer range mimimum
%\newcommand{\dstRange}{\text{dstRange}}  % Destination integer range
%\newcommand{\discreteDst}{\widetilde{\uDst}}   % Destination found using the discretized transformation matrix
%\newcommand{\dDst}{\discreteDst}               % Destination found using the discretized transformation matrix
%\newcommand{\delDst}{\delta\uDst}              % Error in the Destination found using the discretized transformation matrix
%
%\newcommand{\unitT}{\text{uT}}             % Rotated values in the unit range 0:1
%\newcommand{\uT}{\unitT}                   % Rotated values in the unit range 0:1
%\newcommand{\intT}{\text{iT}}              % Rotated values in the integer range tMin:tMax
%\newcommand{\iT}{\intT}                    % Rotated values in the integer range tMin:tMax
%\newcommand{\tMax}{\text{tMax}}            % Rotated values integer range maximum
%\newcommand{\tMin}{\text{tMin}}            % Rotated values integer range mimimum
%\newcommand{\tRange}{\text{tRange}}        % Rotated values integer range
%\newcommand{\discreteT}{\widetilde{\uT}}   % Rotated values found using the discretized transformation matrix
%\newcommand{\dT}{\discreteT}               % Rotated values found using the discretized transformation matrix
%\newcommand{\delT}{\delta\uT}              % Error in the Rotated values found using the discretized transformation matrix
%
%\newcommand{\unitSrc}{\text{uSrc}}       % Source in the unit range 0:1
%\newcommand{\uSrc}{\unitSrc}             % Source in the unit range 0:1
%\newcommand{\intSrc}{\text{iSrc}}        % Source in the integer range srcMin:srcMax
%\newcommand{\iSrc}{\intSrc}              % Source in the integer range srcMin:srcMax
%\newcommand{\srcMax}{\text{srcMax}}      % Source integer range maximum
%\newcommand{\srcMin}{\text{srcMin}}      % Source integer range mimimum
%\newcommand{\srcRange}{\text{srcRange}}  % Source integer range
%
%\newcommand{\unitX}{\text{uX}}       % Source in the unit range 0:1
%\newcommand{\uX}{\unitX}             % Source in the unit range 0:1
%\newcommand{\intX}{\text{iX}}        % Source in the integer range xMin:xMax
%\newcommand{\iX}{\intX}              % Source in the integer range xMin:xMax
%\newcommand{\xMax}{\text{xMax}}      % Source integer range maximum
%\newcommand{\xMin}{\text{xMin}}      % Source integer range mimimum
%\newcommand{\xRange}{\text{xRange}}  % Source integer range
%
%\newcommand{\unitY}{\text{uY}}       % Destination in the unit range 0:1
%\newcommand{\uY}{\unitY}             % Destination in the unit range 0:1
%\newcommand{\intY}{\text{iY}}        % Destination in the integer range yMin:yMax
%\newcommand{\iY}{\intY}              % Destination in the integer range yMin:yMax
%\newcommand{\yMax}{\text{yMax}}      % Destination integer range maximum
%\newcommand{\yMin}{\text{yMin}}      % Destination integer range mimimum
%\newcommand{\yRange}{\text{yRange}}  % Destination integer range
%
%\newcommand{\unitR}{\text{uR}}
%\newcommand{\uR}{\unitR}
%\newcommand{\intR}{\text{iR}}
%\newcommand{\iR}{\intR}
%\newcommand{\discreteR}{\widetilde{\uR}}
%\newcommand{\dR}{\discreteR}
%\newcommand{\delR}{\delta\uR}
%\newcommand{\rRange}{\text{rRange}}  % the discretization of the rotation matrix

\chapter{Skin Statistics}\label{sec:ChapSkin}
\epstopdfsetup{outdir=Chapter3/Figs/PDF/}
\ifpdf
    \graphicspath{{Chapter3/Figs/Raster/}{Chapter3/Figs/PDF/}{Chapter3/Figs/}}
\else
    \graphicspath{{Chapter3/Figs/Vector/}{Chapter3/Figs/}}
\fi


<Intro here>

<Chromatic Target Model>
Describe the object as a series--as a blob it's essentially one color. so we're not looking for things that have a lot of chromatic variation, what we're looking for is essentially things of one color, but has variation around its average color, which can be described as a product of two 1D Gaussians--let's just say as a 2D Gaussian distribution in the chromatic space. We're doing, like, chromatic statistics here; we're starting from some knowledge and that knowledge comes from the paper, so we reference the papers which have done chromatic skin statistics and they've done a variety of different approaches, but found it's describes well as a 2D Gaussian, so we expect this will be true for us as well. The difference with our approach is that we have fine control over the color spae, and so we are going to orient the color space so that the 2D Gaussian can be written as the product of two 1D Gaussians, i.e. the major and minor axes of the 1D Gaussians line up with the chromatic axes of our color space.

The goal of this is to get a value of $\sigma$, two standard deviations (a vector), the position for the mean $\mu$, and an angle $\theta$, the angle of the major axis of the 2D Gaussian found in the $\theta = 0$ color space. This then allows us to use the methods presented in chapter 2 to design a bespoke color space which will preserve all the chromatic information about the target model.

<Algorithm for Generating the Model>
Here we present the algorithm which is used to generate the chromatic model. It's assumed we have RGB image sets for the target with simple, monochromatic backgrounds.

[1. RGB in allocation]
All the information which is present in the 8-bit unsigned images is in an RGB space. The first problem is that we have a large image set with large images. We're not interested in what these images are pictures of; we're only interested in the individual pixel values themselves. So, we produce a 3D histogram with one bin for each RGB combination. This gives us a histogram with 256x256x256 bins. This is a very large data set; perhaps unnecessarily so. But it's easier to work with than a set of images, and is guaranteed to contain all the relevant information for the statistics. 

The algorithm is written in MATLAB, and it very simply loads up each image in the set and runs through each pixel, incrementing the corresponding bin. As it's going, it keeps a count of the number of bin allocations, so we have a total pixel count. After it's run through all the images, it find the largest bin and keeps a record of the largest bin count, so we can have a normalized bin when requested.


[2. Skinning the Bins]
Next, the bins which are at the extreme edges (i.e. the ones which correspond to the outer faces of the RGB cube) are set equal to 0 with a specified depth. For example: if a depth of 3 is requested, bins of positions 0, 1 and 2, and 253, 254 and 255 are set to 0 in all three dimensions, and the total pixel count is adjusted to compensate for the nulled bin counts. This is done to address problems of white-out and black-out as described below.

<Put white-out and black-out stuff in here.>
Naively collapsing the bins along the luminosity axis artificially skews the chromatic distribution along the axis which passed through the luminosity axis; this is easily explained due to white-out and black-out. As luminosity increases or decreases, it will eventually hit the edge of the cube. Having reached its numerical limit, the luminosity slides toward the corner of the cube, resulting in a white or black value.

To accommodate this, we collapse the bins excluding the bins which are clearly suffering from white-out and black-out. This could be done mathematically by taking the bin of the distribution which is furthest from the luminosity axis, and then finding the intersection with the RGB cube when this chromatic value is at its limits, just before it reaches the edge of the cube where it suffers from white-out or black-out. But it's a simple matter to look at the three projections of the 3D LCaCb bins and manually determine the limits for the valid region.

It should be noted that the reason the RGB cube is skinned before rotation because it's not as easy to do in the rotated color space.


[3. Rotating the Bins]
Because each of the bins corresponds to just one RGB value, we can find the equivalent bin in the LCaCb space simply by rotating the bin index. This is done using the un-normalized rotation described in Chapter 2, thereby assuring a 1-to-1 correspondence of the bins. With this done, we now have a set of bins in the LCaCb color space equivalent to that which would be found if we had applied the transform to each of the images and then collected the statistics from the transformed images.


[4. Top and Tail]
Although we've "skinned" the bins, the white and black tips of the cube suffer from white-out and black-out more than any other regions, and there's a tendency for pixel values to converge under the white point and the black point without necessarily hitting the side of the cube first. This can be seen in <insert reference to banana picture>. There's also quite a lot of white and quite a lot of black in pretty much any image. Since we're just interested in the chromatic information, we nullify bin values above a certain threshold and below a certain threshold.


[5. Collapse the Bins]
Because we're modelling the chromatic space and not the luminosity, we now collapse the 3D histogram by summing the bin values along the luminosity axis. So, we now have a 2D histogram in CaCb chromatic space.


[6. De-Speckle the Bin Values]
The obvious idea is to find all the non-zero bins and fit an interpolating function between them. This will effectively remove the empty bin artifacts within the densely-packed region which is the distribution we're interested in. However, the empty bins outside the main distribution are not artifacts and are genuinely empty bins, so removing all the empty bins and then fitting the function joins together any outlying points or secondary distributions corresponding to regions such as the background. We therefore desire a method which will allow us to keep all the non-empty bins and the empty bins outside the main distribution, i.e. all the genuinely empty bins. To achieve this, we designed a Matlab routine which essentially paints a region around each non-zero point, marking it as part of the main distribution. It then takes all the unmarked regions and includes all the empty bins in those regions. So, the set of points which is all the non-empty bins and all the empty bins in the unmarked regions satisfies the requirement, and a simple interpolating function can easily be fitted to those points.


[7. Blob Detection]
Using Mathematica's blob detection algorithm, we can find the patches of chromatic information, which gives us starting values for the standard deviation. We expect there to be two distinct blobs still present: one corresponding to the target, and one to the background --- the background essentially being monochromatic. Steps 1 to 6 have also been followed for background images. 

<Insert background removal section here.>
Having removed the empty bin artifacts and compensated for white-out/black-out effects, the final step is to remove the bin counts of the bins which are associated with the background, thereby leaving a distribution which corresponds to chromatic skin values and which is artifact- and systematic-error-free. With the chromatic bins processed as they have been so far, it is clear that there is a distinct distribution for the skin and a distinct distribution for the background. However, a distribution for the background was produced earlier, compensating for the iPhone's pre-AP-layer processing. Background removal is automated using a Matlab function which will negate the bins from one sample set using the distribution found for a second sample set.


This allows us to identify which blobs apply to the background, and sweep it clean.


[8. The Gaussian Fit]
We now have a histogram which has bin values relevant to the target and no others. We now fit a 2D Gaussian to a normalized histogram values, initializing the routine with the values for the mean $\mu$ and the rough elliptical axis lengths for the standard deviation $\sigma$ provided by the blob detection.

<Insert bit where we copy over the angle here.>  

As a check, we started the process again from step 3, this time using the value of $\theta$ found by the Gaussian fit, until the value remains consistent.




In order to identify the range of values for the skin space, a large number of skin samples were taken from photographs from the Humane project by Angelica Dass, an ongoing "chromatic inventory" art project which aims to compile every possible human skin color, categorized by the PANTONE guide color classification system~\cite{Dass2012}. The skin colors catalogued thus far are independent of race or ethnicity, so the samples are representative of human skin tones in general.

The image set consists of approximately 200 skin samples --- each of which shows only skin --- which are placed in a single directory in the file system. In accordance to our assumption that luminosity is not a significant factor in our skin model, we then perform the transformation initially with the value of $\theta$ equal to 0. The Matlab code collects frequency data for the rotated color space, incrementing the counts of a three-dimensional array of bins which span the color space. Viewing the frequency data along each of the three axes reveals that the skin image characteristics are spread widely in luminosity, but are quite confined in hue and saturation as illustrated in Figure~\ref{fig:InitBins}.


\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{Chapter3/Figs/InitialBins.eps}
    \caption{Initial set of bins.}  \label{fig:InitBins}
\end{figure}


Aside from differing lighting, this is consistent with the notion that skin has a distinct pigmentation and justifies our attempt to find an appropriate color space disregarding luminosity. In doing so, the distribution of the skin color characteristics neatly fit into a 2-dimensional Gaussian distribution. The Matlab code produces a fit with a 2-dimensional Gaussian distribution and provides an angle relative to the orientation of the Gaussian fit to the skin sample distribution in the current color space.

Given that we are free to choose the orientation of the color space about the luminosity axis, the Matlab code allows us to find an orientation $\theta$ of the color space about the luminosity axis in which the distribution can be expressed as a product of 1-dimensional Gaussians along the axes. The final resulting distribution is presented in Figure~\ref{fig:DistributionAndGaussianFit}.


\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{Chapter3/Figs/crosshairFigureFinal.eps}
    \caption{Distribution and Gaussian fit to the chromatic pixel values in the new color space.}  \label{fig:DistributionAndGaussianFit}
\end{figure}


For numerical reasons, the value for $\theta$ was found iteratively by performing the color space transformation and the statistical fit until the value for $\theta$ converged. (See Figure~\ref{fig:ConvergenceTheta}.)

\section{iPhone Camera Characteristics} \label{sec:iPhoneCameraCharacteristics}

Unlike more general cameras, the iPhone's camera performs certain pre-processing tasks on the raw image before it reaches the AP layer. Typically, cameras have a specific white point value, which is the value corresponding to white. It isn't necessarily the corner of the RGB cube; finding this value is part of the camera calibration. It also determines the orientation of the luminosity axis, which passes through zero to the white point. This is why all pre-defined color space functions have an implicit white point correction. However, the iPhone's white point is always set to the corner of the RGB cube before the image reaches the AP layer. So, when developing an algorithm for the iPhone, white point correction is not necessary, while on other devices the algorithm may need to be adapted accordingly.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.80\textwidth]{Chapter3/Figs/lxy_general_white_point.eps}
    \caption{The white point for the general skin sample set described in Section~\ref{sec:SkinStatistics}.}  \label{fig:WhitePoint}
\end{figure}

While gathering skin statistics for the purposes of this project, the original approach involved taking photos of individual skin --- each with distinct color characteristics --- taken under different lighting conditions with a constant background using the iPhone camera. The background was included in order to obtain data on the edges of the skin. The background would be photographed, then again with each individual's hand over the same background. Afterward, the statistics would be collected and the background removed by negating the background statistics.

Surprisingly, this approached failed to work; the background reappeared (Figure~\ref{fig:BGFailure}).

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.60\textwidth]{Chapter3/Figs/xy_bg_failed.eps}
    \caption{Initial attempt at removing background; unsuccessful.} \label{fig:BGFailure}
\end{figure}

The background statistics changed with the skin present in the photo. This is because the iPhone adjusts to images with very strong color characteristics. This is an undocumented feature of the iPhone processing. The only way to compensate for this unwelcome pre-processing is to photograph the background with a strongly contrasting object present, but one which is easily cropped out of the image before the background stats are collected. After collecting the statistics again, the result was much improved (Figure~\ref{fig:BGSuccess}).

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.60\textwidth]{Chapter3/Figs/bg_cap.eps}
    \caption{The red marker cap contrasts with the green background.}  \label{fig:BGCap}
\end{figure}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.60\textwidth]{Chapter3/Figs/xy_bg_success.eps}
    \caption{Successful background removal.}  \label{fig:BGSuccess}
\end{figure}

In a real world context, it is relatively safe to presume that the scene will be chromatically complex enough that the color correction won't be detrimental to detection, and perhaps even beneficial under unusual lighting conditions. But for gathering statistics, it proved to be a massive pain.


\section{Implementation of Skin Color Space Statistics in Matlab}\label{sec:SkinColorSpaceStatsMatlab}

A naive approach is to take a directory of images and process them using our color space transformation with the free angle $\theta$, processing them into three-dimensional pixel value bins. It was discovered that the region of interest is relatively small in this 3D space, so it was made possible the use of a bin of width greater than 1 lumio-chromatic value. However, it is quickly found that the region of interest is so small that using a more encompassing lumio-chromatic bin is actually detrimental to the numerics involved in finding and appropriate Gaussian fit, so a lumio-chromatic bin of width 1 is used.

Because the region is so small, when the transformation is applied, we must also retain all the information therein. Initially, we did not know this; our transformed images were represented as the same data type as the original. But because the transformed information is a less efficient representation of the original information, a significant amount of that information is lost.

\begin{figure}[h!]
  \centering
    \includegraphics[width=\textwidth]{Chapter3/Figs/ConvergenceOfSkinSpaceFinal.eps}
    \caption{Convergence of color space orientation $\theta$.}  \label{fig:ConvergenceTheta}
\end{figure}

A better approach would be to iterate over the free angle $\theta$ of the Gaussian fit of the two-dimensional bin, which was found by collapsing the 3D bins along the luminosity axis, until convergence; at best, convergence was achieved after 3 iterations. Unfortunately, this approach --- though conceptually straightforward --- is very wasteful; all of the necessary information can be found in the RGB bin statistics.

Given that we are unable to apply this process in a reasonably efficient manner to individuals and general samples, if this project is to be finished sometime this century, a more nuanced approach is necessary.

\subsection{Transformation with Zero Angle}\label{sec:TransWithZeroAngle}

The more interpretable statistics for this project is a set of bins which contains all the information in the RGB bins, but is oriented such that there is a luminosity axis and two chromatic axes. Although the rotation matrices aren't unique, a set can be chosen and an angle $\theta$ determined in the chromatic space to be zero.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/xy_Polygon.eps}
    \caption{The projection along the L axis showing the chromatic space with a free rotational angle of 0.}  \label{fig:xyPolygon}
\end{figure}



\subsection{Removing Zeroes}\label{sec:RemovingZeroes}

The obvious idea is to find all the non-zero bins and fit an interpolating function between them. This will effectively remove the empty bin artifacts within the densely-packed region which is the distribution we're interested in. However, the empty bins outside the main distribution are not artifacts and are genuinely empty bins, so removing all the empty bins and then fitting the function joins together any outlying points or secondary distributions corresponding to regions such as the background. We therefore desire a method which will allow us to keep all the non-empty bins and the empty bins outside the main distribution, i.e. all the genuinely empty bins. To achieve this, we designed a Matlab routine which essentially paints a region around each non-zero point, marking it as part of the main distribution. It then takes all the unmarked regions and includes all the empty bins in those regions. So, the set of points which is all the non-empty bins and all the empty bins in the unmarked regions satisfies the requirement, and a simple interpolating function can easily be fitted to those points.

%<flow chart, maybe? Or maybe at the end; we'll see.>

\subsection{White-Out and Black-Out}\label{sec:WhiteOutBlackOut}

Naively collapsing the bins along the luminosity axis artificially skews the chromatic distribution along the axis which passed through the luminosity axis; this is easily explained due to white-out and black-out. As luminosity increases or decreases, it will eventually hit the edge of the cube. Having reached its numerical limit, the luminosity slides toward the corner of the cube, resulting in a white or black value.

To accommodate this, we collapse the bins excluding the bins which are clearly suffering from white-out and black-out. This could be done mathematically by taking the bin of the distribution which is furthest from the luminosity axis, and then finding the intersection with the RGB cube when this chromatic value is at its limits, just before it reaches the edge of the cube where it suffers from white-out or black-out. But it's a simple matter to look at the three projections of the 3D LCaCb bins and manually determine the limits for the valid region.

%<Insert white-out/black-out bins here>

\subsection{Removing the Background Distribution}\label{sec:RemovingBGDistribution}

Having removed the empty bin artifacts and compensated for white-out/black-out effects, the final step is to remove the bin counts of the bins which are associated with the background, thereby leaving a distribution which corresponds to chromatic skin values and which is artifact- and systematic-error-free. With the chromatic bins processed as they have been so far, it is clear that there is a distinct distribution for the skin and a distinct distribution for the background. However, a distribution for the background was produced earlier, compensating for the iPhone's pre-AP-layer processing. Background removal is automated using a Matlab function which will negate the bins from one sample set using the distribution found for a second sample set.

%<Graph showing the overlap of the background and a skin background sample set; briefly describe what that shows.>

\subsection{Results}\label{sec:Results}

We're trying to develop a skin model from the Humane project, which provides a set which spans all the different skin tones. Although these images are not captured using the iPhone camera and thus suffer from a white point which does not correspond with the iPhone's white point (at least at the AP layer), it does provide a sufficient statistical basis to determine a color space region which is spanned by human skin. However, because of the iPhone camera's characteristics after pre-processing and the fact that the application needs to respond to an individual's skin, the investigation of skin tone characteristics for individuals is necessary.

To that effect, we selected three individuals with different skin tones; ordering by pigmentation from dark to light, we will henceforth refer to these as subjects F, N and J. Statistics were collected for the three subjects using the procedure outlined previously in this section. A two-dimensional Gaussian was fitted to the distribution for each individual.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/FHands_XY_fBin.eps}
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/FHands_XY_gFit.eps}
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/NHands_XY_fBin.eps}
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/NHands_XY_gFit.eps}
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/JHands_XY_fBin.eps}
    \includegraphics[width=0.49\textwidth]{Chapter3/Figs/JHands_XY_gFit.eps}
    \caption{The CaCb bins after processing and the Gaussian fit.}  \label{fig:FBinAndGFit}
\end{figure}

The individual statistics are as follows:
\newline

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
& \multicolumn{2}{|c|}{Mean ($\mu$)} & \multicolumn{2}{|c|}{Standard Deviation ($\sigma$)} & \multicolumn{2}{|c|}{Angle ($\theta$)} \\\hline
& X & Y & X & Y & Major Axis & Minor Axis \\\hline
F & 0.4249 & 0.3335 & 0.0081 & 0.0251 & -0.7724 & 0.7984 \\\hline
N & 0.4281 & 0.3443 & 0.0080 & 0.0195 & -0.5549 & 0.5969 \\\hline
J & 0.4022 & 0.3302 & 0.0119 & 0.0253 & -0.8954 & 0.6754 \\\hline
\end{tabular}
\newline
\vspace{0.5 cm}
\newline
The statistics for the general sample set are as follows:
\newline

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
& \multicolumn{2}{|c|}{Mean ($\mu$)} & \multicolumn{2}{|c|}{Standard Deviation ($\sigma$)} & \multicolumn{2}{|c|}{Angle ($\theta$)} \\\hline
& X & Y & X & Y & Major Axis & Minor Axis \\\hline
General & 0.4820 & 0.4253 & 0.0072 & 0.0108 & -0.1174 & 1.4534 \\\hline
\end{tabular}



