%*****************************************************************************************
%*********************************** Fourth Chapter **************************************
%*****************************************************************************************

\chapter{Future Work and Discussion}

\ifpdf
    \graphicspath{{Chapter5/Figs/Raster/}{Chapter5/Figs/PDF/}{Chapter5/Figs/}}
\else
    \graphicspath{{Chapter5/Figs/Vector/}{Chapter5/Figs/}}
\fi
\section{Results and Evaluation}\label{sec:ResultsAndEvaluation}

\section{Future Applications}\label{sec:FutureApplications}


\subsection{Medical Applications}\label{sec:MedicalApplications}

\subsection{Scientific Applications}\label{sec:ScientificApplications}

\subsection{Computer Vision Applications}\label{sec:ComputerVisionApplications}

\section{Improvements and Extensions}\label{sec:ImprovementsAndExtensions}


\subsection{Color Space Algorithm}\label{sec:ColorSpaceAlgorithmImprovements}


\subsubsection{Generalizing the Rotation}\label{sec:GeneralizingTheRotation}
In Chapter 2, we derived an expression for a rotation matrix consisting entirely of integers which rotates the RGB pixel values into a custom color space with a luminosity axis and two chromatic axes. The orientation of the chromatic axes is specified using a free rotation $\theta$ about the luminosity axis. The only restriction on the free parameter $\theta$ is that which results from the requirement for the matrix to consist entirely of integer values within a specific range. The question remains: is it possible to achieve a similar result without restricting one of the axes?

In this work, we assumed that an 8-bit per-channel value of $(255, 255, 255)$ corresponds with white. This, however is a result of the pre-processing on the iPhone. Extending this work to other devices or accessing the iPhone's RAW camera feed, it may be desirable to use a different point for the camera's white point. Another reason is to adjust for local ambient light conditions; it is common in digital photography to choose a pixel value from a reference white object to set a white point for the image, allowing a color correction to be performed.

An arbitrary rotation is determined by three angles, and so it's conceivable that the work of Chapter 2 (Section \ref{sec:ConstructingANewColorSpace}) could be repeated for this arbitrary rotation. Whilst it may be possible, an alternative approach may be preferable given the complexity of the general rotation equations. First we assume that the solution exists, then form an initial guess at the solution by quantizing the floating point representation of the matrix. Next, we find the maximum error produced by our approximate quantized rotation by rotating the corners of the RGB cube and comparing the results, then numerically search around this approximation for improvements. The question that remains is what search area should be included.

<math here>

Because the general rotation matrix can be split into the product of three individual matrices, each of which is dependent on only one of the three free parameters, the work in Section \ref{sec:ConstructingANewColorSpace} could be repeated relatively straightforwardly for each of these three individual matrices, and from this --- for a given quantization criteria --- a minimum and a maximum angle step size (Figure \ref{fig:PtbToChan}). If we have for the separate matrices a minimum and a maximum step size, it's a reasonable idea to search around our initial approximation in steps of the minimum step size to either side out to a maximum distance of the maximum step size. For each of the three angles, we search within a cube with sides defined by the maximum step sizes for each of those rotation matrices. On a cubic grid defined by their minimum step sizes. The result of this is that there is a relatively small set of possible optimized choices. Although this is not solving the problem to the same degree that was done in \ref{sec:ConstructingANewColorSpace}, where we reduced it to a mathematical function, it provides a practical way of achieving the same results without excessive computational effort in the setup. 

\subsubsection{Multi-Channel Color Spaces}\label{sec:MultiChannelColorSpaces}

As mentioned in Chapter 1, the RGB color space is an approximation to the full spectrum of light. However, commercially-available cameras which are not confined to the three-channel approximation are becoming available; such a multi-channel image contains far more information about the objects in frame. So where the camera is being used for computer vision tasks where the objective is not to produce a pretty picture to present to the human eye, this allows the chromatic space to discriminate between different objects and surfaces in ways which are unseen by the standard RGB camera point of view.

The basic design of these multi-spectral cameras is essentially the same as for the RGB cameras where the spectrum of light on each point in the scene (roughly speaking, see Chapter 1) is presented by a combination of Gaussians, the only difference being we have more Gaussians; each channel can therefore be considered an orthogonal axis in a multi-dimensional color space. The multi-dimensional color space contains a point which corresponds to white, so it is just as possible to construct a color space with a luminosity axis and $n-1$ chromatic axes for an $n$-channel image. Transformation to this color space is defined by a multi-dimensional rotation; this rotation could be optimized in a similar way to that presented in Chapter 2. However, our requirement in Chapter 2 was that the immediate result of the rotation would fit into a data type no more than twice the bit depth of each channel. An $n$-channel color space will be rotated by an $n$ x $n$ rotation matrix; if we have $m$ bits per channel and the quantized rotation matrix is expressed in $l$-bit integers, the result is $l + n + (n-1)$.

\begin{figure}
  \centering
  \begin{tabular}{cc}
  \subfloat[Triwave EC701.]{
    \includegraphics[width=.49\textwidth]{Chapter5/Figs/multispec-triwave.jpg}
    }&
  \subfloat[HyperCam by University of Washington and Microsoft Research.]{
    \includegraphics[width=.49\textwidth]{Chapter5/Figs/multispec-hypercam.jpg}
    } \\
    \multicolumn{2}{c}{
    \subfloat[Optec multi-spectral camera.]{
        \includegraphics[width=.49\textwidth]{Chapter5/Figs/multispec-optec.jpg}
    }
    }
  \end{tabular}
  \caption{A variety of multi-spectral cameras currently in use.}
  \label{fig:MultiSpectralCameras}
\end{figure}

\subsubsection{Using the RAW Image From the Camera}\label{sec:UsingTheRAWImageFromTheCamera}

\subsection{Implementation Improvements}\label{sec:ImplementationImprovements}

\subsubsection{An Empirical WoBo Algorithm}\label{sec:EmpicialWoBoAlgorithm}

\subsubsection{Auto-Adjusting the Variance}\label{sec:AutoAdjustingTheVariance}

\subsubsection{Statistics Gathering Method for the App}\label{sec:StatisticsGatheringMethod}

\subsubsection{Improved ICWaS Alignment}\label{sec:ImprovedICWaSAlignment}

\subsubsection{More Designed Metric for Mechanical Stress}\label{sec:MoreDesignedMetricforMechanicalStress}


\section{Conclusion}\label{sec:ConclusionCh5}

The finger press algorithm is really a simple application to demonstrate the viability of detecting blood movement using a standard camera on a mobile device. Many previous authors have dismissed using bespoke color spaces for such applications simply because the color space transform itself is computationally intensive and significantly loses information when applied using standard, off-the-library-shelf color spaces. It's fundamentally difficult to use with the loss of information, with white-out and black-out, and the computational intensity right at the front of the algorithm have meant that such techniques have seen little use.

It is hoped that, with the rigorous optimization of the transform itself --- which is considered in great and incredibly tedious detail in chapter 2 --- that these color spaces can see greater application in the future, although it's recognized that the level of attention that's currently required to make the routine as efficient at the one designed herein will likely be beyond the patience of many practitioners, some of whom are medical professionals and not computer scientists. Also, it is hoped that the work presented here has addressed the concerns about the loss of information associated. This surely must be the case because the color space transform is designed not to lose any information from the RGB color space.

Finally, the use of a Gaussian model for the skin color space has been the source of much debate; some authors insist that the Gaussians be extended to the three-dimensional space, but hopefully it can be seen from this work that a luminosity Gaussian distribution is an artifact due to white-out and black-out, and so is not necessary. The potential gains of using such a luminosity distribution would appear to be gained using the 2-bit Canny edge detection algorithm outlined in~\ref{sec:ImprovedContourDetection}.

The color space algorithm has many possible future applications as an aid to diagnostics, however specialist cameras will always outperform in this area. Also, mechanical stress is not limited to the end of the fingers; knuckles significantly whiten when flexed, so the color space could aid in hand posture work, as would the Canny edge detection methods --- although not presented here during the design of the algorithm --- it was striking how clearly other hand features presented themselves. For instance, it was very tempting to attempt to attach a feature descriptor to the perpendicular creases in the knuckles.

Although not presented here, the majority of the time and effort involved in producing this work went into the furthering of the OpenCV library, which is an open source project hosted on GitHub. The reason this occupied so much of the time is because, at the start of this project, there was no working implementation for iOS. Additionally, the new C++11 standard was released and many of the associated libraries were upgraded, as is so oftenthe case with computer science projects, a significant amount of time had to be dedicated to actually making the code and the libraries work on the selected device appropriately. Probably the most significant contribution this project has made to the library is the extension of the internal data types, which were necessary both for the C++11 standard and the 2-bit and 4-bit types which allowed for the optimization of many of the heavy-duty routines.

As for the finger pressure detector, it could be extended to detect the whole hand and to track the individual digits; with work and some machine learning algorithms, it should be possible to enable the app to measure the degree of pressure, which would be ideally suited to a project such as a paper piano, or perhaps even an augmented reality keyboard.